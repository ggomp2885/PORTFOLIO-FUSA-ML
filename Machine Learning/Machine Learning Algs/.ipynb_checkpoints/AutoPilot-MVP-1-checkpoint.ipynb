{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Amazon SageMaker Autopilot Candidate Definition Notebook\n",
    "\n",
    "This notebook was automatically generated by the AutoML job **Funders-USA-SEC-data-MVP-1**.\n",
    "This notebook allows you to customize the candidate definitions and execute the SageMaker Autopilot workflow.\n",
    "\n",
    "The dataset has **17** columns and the column named **Funding_Success** is used as\n",
    "the target column. This is being treated as a **BinaryClassification** problem. The dataset also has **2** classes.\n",
    "This notebook will build a **[BinaryClassification](https://en.wikipedia.org/wiki/Binary_classification)** model that\n",
    "**maximizes** the \"**ACCURACY**\" quality metric of the trained models.\n",
    "The \"**ACCURACY**\" metric provides the percentage of times the model predicted the correct class.\n",
    "\n",
    "As part of the AutoML job, the input dataset has been randomly split into two pieces, one for **training** and one for\n",
    "**validation**. This notebook helps you inspect and modify the data transformation approaches proposed by Amazon SageMaker Autopilot. You can interactively\n",
    "train the data transformation models and use them to transform the data. Finally, you can execute a multiple algorithm hyperparameter optimization (multi-algo HPO)\n",
    "job that helps you find the best model for your dataset by jointly optimizing the data transformations and machine learning algorithms.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "Look for sections like this for recommended settings that you can change.\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Sagemaker Setup](#Sagemaker-Setup)\n",
    "    1. [Downloading Generated Candidates](#Downloading-Generated-Modules)\n",
    "    1. [SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration](#SageMaker-Autopilot-Job-and-Amazon-Simple-Storage-Service-(Amazon-S3)-Configuration)\n",
    "1. [Candidate Pipelines](#Candidate-Pipelines)\n",
    "    1. [Generated Candidates](#Generated-Candidates)\n",
    "    1. [Selected Candidates](#Selected-Candidates)\n",
    "1. [Executing the Candidate Pipelines](#Executing-the-Candidate-Pipelines)\n",
    "    1. [Run Data Transformation Steps](#Run-Data-Transformation-Steps)\n",
    "    1. [Multi Algorithm Hyperparameter Tuning](#Multi-Algorithm-Hyperparameter-Tuning)\n",
    "1. [Model Selection and Deployment](#Model-Selection-and-Deployment)\n",
    "    1. [Tuning Job Result Overview](#Tuning-Job-Result-Overview)\n",
    "    1. [Model Deployment](#Model-Deployment)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Model Testing\n",
    "\n",
    "Before you launch the SageMaker Autopilot jobs, we'll setup the environment for Amazon SageMaker\n",
    "- Check environment & dependencies.\n",
    "- Create a few helper objects/function to organize input/output data and SageMaker sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimal Environment Requirements**\n",
    "\n",
    "- Jupyter: Tested on `JupyterLab 1.0.6`, `jupyter_core 4.5.0` and `IPython 6.4.0`\n",
    "- Kernel: `conda_python3`\n",
    "- Dependencies required\n",
    "  - `sagemaker-python-sdk>=2.19.0`\n",
    "    - Use `!pip install sagemaker==2.19.0` to download this dependency.\n",
    "    - Kernel may need to be restarted after download.\n",
    "- Expected Execution Role/permission\n",
    "  - S3 access to the bucket that stores the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Generated Modules\n",
    "Download the generated data transformation modules and an SageMaker Autopilot helper module used by this notebook.\n",
    "Those artifacts will be downloaded to **Funders-USA-SEC-data-MVP-1-artifacts** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p Funders-USA-SEC-data-MVP-1-artifacts\n",
    "!aws s3 sync s3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1/sagemaker-automl-candidates/pr-1-93f644fc87dd4359b02b3f5674282e148942c514864c4937956e91e3be/generated_module Funders-USA-SEC-data-MVP-1-artifacts/generated_module --only-show-errors\n",
    "!aws s3 sync s3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1/sagemaker-automl-candidates/pr-1-93f644fc87dd4359b02b3f5674282e148942c514864c4937956e91e3be/notebooks/sagemaker_automl Funders-USA-SEC-data-MVP-1-artifacts/sagemaker_automl --only-show-errors\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"Funders-USA-SEC-data-MVP-1-artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Autopilot Job and Amazon Simple Storage Service (Amazon S3) Configuration\n",
    "\n",
    "The following configuration has been derived from the SageMaker Autopilot job. These items configure where this notebook will\n",
    "look for generated candidates, and where input and output data is stored on Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This notebook is initialized to use the following configuration: \n",
       "        <table>\n",
       "        <tr><th colspan=2>Name</th><th>Value</th></tr>\n",
       "        <tr><th>General</th><th>Role</th><td>arn:aws:iam::570124035543:role/service-role/AmazonSageMaker-ExecutionRole-20200602T133715</td></tr>\n",
       "        <tr><th rowspan=2>Base AutoML Job</th><th>Job Name</th><td>Funders-USA-SEC-data-MVP-1</td></tr>\n",
       "        <tr><th>Base Output S3 Path</th><td>s3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1</td></tr>\n",
       "        <tr><th rowspan=5>Interactive Job</th><th>Job Name</th><td>Funders-US-notebook-run-11-04-05-35</td></tr>\n",
       "        <tr><th>Base Output S3 Path</th><td>s3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1/Funders-US-notebook-run-11-04-05-35</td></tr>\n",
       "        <tr><th>Data Processing Trained Model Directory</th><td>s3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1/Funders-US-notebook-run-11-04-05-35/data-processor-models</td></tr>\n",
       "        <tr><th>Data Processing Transformed Output</th><td>s3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1/Funders-US-notebook-run-11-04-05-35/transformed-data</td></tr>\n",
       "        <tr><th>Algo Tuning Model Output Directory</th><td>s3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1/Funders-US-notebook-run-11-04-05-35/multi-algo-tuning</td></tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker_automl import uid, AutoMLLocalRunConfig\n",
    "\n",
    "# Where the preprocessed data from the existing AutoML job is stored\n",
    "BASE_AUTOML_JOB_NAME = 'Funders-USA-SEC-data-MVP-1'\n",
    "BASE_AUTOML_JOB_CONFIG = {\n",
    "    'automl_job_name': BASE_AUTOML_JOB_NAME,\n",
    "    'automl_output_s3_base_path': 's3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1',\n",
    "    'data_transformer_image_repo_version': '0.2-1-cpu-py3',\n",
    "    'algo_image_repo_versions': {'xgboost': '1.0-1-cpu-py3', 'linear-learner': 'latest', 'mlp': 'training-cpu'},\n",
    "    'algo_inference_image_repo_versions': {'xgboost': '1.0-1-cpu-py3', 'linear-learner': 'latest', 'mlp': 'inference-cpu'}\n",
    "}\n",
    "\n",
    "# Path conventions of the output data storage path from the local AutoML job run of this notebook\n",
    "LOCAL_AUTOML_JOB_NAME = 'Funders-US-notebook-run-{}'.format(uid())\n",
    "LOCAL_AUTOML_JOB_CONFIG = {\n",
    "    'local_automl_job_name': LOCAL_AUTOML_JOB_NAME,\n",
    "    'local_automl_job_output_s3_base_path': 's3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1/{}'.format(LOCAL_AUTOML_JOB_NAME),\n",
    "    'data_processing_model_dir': 'data-processor-models',\n",
    "    'data_processing_transformed_output_dir': 'transformed-data',\n",
    "    'multi_algo_tuning_output_dir': 'multi-algo-tuning'\n",
    "}\n",
    "\n",
    "AUTOML_LOCAL_RUN_CONFIG = AutoMLLocalRunConfig(\n",
    "    role='arn:aws:iam::570124035543:role/service-role/AmazonSageMaker-ExecutionRole-20200602T133715',\n",
    "    base_automl_job_config=BASE_AUTOML_JOB_CONFIG,\n",
    "    local_automl_job_config=LOCAL_AUTOML_JOB_CONFIG,\n",
    "    security_config={'EnableInterContainerTrafficEncryption': False, 'VpcConfig': {}})\n",
    "\n",
    "AUTOML_LOCAL_RUN_CONFIG.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Pipelines\n",
    "\n",
    "The `AutoMLLocalRunner` keeps track of selected candidates and automates many of the steps needed to execute feature engineering and tuning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_automl import AutoMLInteractiveRunner, AutoMLLocalCandidate\n",
    "\n",
    "automl_interactive_runner = AutoMLInteractiveRunner(AUTOML_LOCAL_RUN_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Candidates\n",
    "\n",
    "The SageMaker Autopilot Job has analyzed the dataset and has generated **6** machine learning\n",
    "pipeline(s) that use **3** algorithm(s). Each pipeline contains a set of feature transformers and an\n",
    "algorithm.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. The resource configuration: instance type & count\n",
    "1. Select candidate pipeline definitions by cells\n",
    "1. The linked data transformation script can be reviewed and updated. Please refer to the [README.md](./Funders-USA-SEC-data-MVP-1-artifacts/generated_module/README.md) for detailed customization instructions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp0-xgboost](Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp0.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-11 04:05:38,382 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:05:38,384 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:05:38,400 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n",
      "2021-02-11 04:05:38,402 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:05:38,403 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:05:38,471 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n",
      "2021-02-11 04:05:38,473 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:05:38,474 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:05:38,483 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp0\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp1-xgboost](Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp1.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-11 04:05:42,689 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:05:42,691 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:05:42,710 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n",
      "2021-02-11 04:05:42,714 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:05:42,715 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:05:42,734 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n",
      "2021-02-11 04:05:42,737 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:05:42,738 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:05:42,756 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp1\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp2-linear-learner](Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp2.py)**: This data transformation strategy first transforms 'numeric' features using [combined RobustImputer and RobustMissingIndicator](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [QuantileExtremeValuesTransformer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustPCA](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/decomposition/robust_pca.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *linear-learner* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-11 04:07:02,386 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:02,387 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:07:02,398 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n",
      "2021-02-11 04:07:02,400 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:02,400 WARNING sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n",
      "2021-02-11 04:07:02,411 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:07:02,412 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:02,412 WARNING sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n",
      "2021-02-11 04:07:02,423 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp2\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"linear-learner\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp3-xgboost](Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp3.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-11 04:07:03,449 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:03,451 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:07:03,462 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n",
      "2021-02-11 04:07:03,464 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:03,464 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:07:03,483 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n",
      "2021-02-11 04:07:03,485 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:03,486 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:07:03,495 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp3\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp4-xgboost](Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp4.py)**: This data transformation strategy first transforms 'numeric' features using [RobustImputer (converts missing values to nan)](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py), 'categorical' features using [ThresholdOneHotEncoder](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/encoders.py). It merges all the generated features and applies [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *xgboost* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-11 04:07:04,043 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:04,044 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:07:04,055 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n",
      "2021-02-11 04:07:04,056 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:04,057 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:07:04,067 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n",
      "2021-02-11 04:07:04,068 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:04,069 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:07:04,078 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp4\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"application/x-recordio-protobuf\",\n",
    "        \"sparse_encoding\": True\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"xgboost\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[dpp5-mlp](Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp5.py)**: This data transformation strategy transforms 'numeric' features using [RobustImputer](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/impute/base.py) followed by [RobustStandardScaler](https://github.com/aws/sagemaker-scikit-learn-extension/blob/master/src/sagemaker_sklearn_extension/preprocessing/data.py). The\n",
    "transformed data will be used to tune a *mlp* model. Here is the definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-11 04:07:04,381 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:04,382 INFO sagemaker.image_uris: Defaulting to only available Python version: py3\n",
      "2021-02-11 04:07:04,390 INFO sagemaker.image_uris: Defaulting to only supported image scope: cpu.\n",
      "2021-02-11 04:07:04,392 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:04,393 WARNING sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: training-cpu.\n",
      "2021-02-11 04:07:04,401 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:07:04,402 INFO sagemaker.image_uris: Same images used for training and inference. Defaulting to image scope: inference.\n",
      "2021-02-11 04:07:04,403 WARNING sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: inference-cpu.\n",
      "2021-02-11 04:07:04,417 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.select_candidate({\n",
    "    \"data_transformer\": {\n",
    "        \"name\": \"dpp5\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "            \"volume_size_in_gb\":  50\n",
    "        },\n",
    "        \"transform_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"transforms_label\": True,\n",
    "        \"transformed_data_format\": \"text/csv\",\n",
    "        \"sparse_encoding\": False\n",
    "    },\n",
    "    \"algorithm\": {\n",
    "        \"name\": \"mlp\",\n",
    "        \"training_resource_config\": {\n",
    "            \"instance_type\": \"ml.m5.4xlarge\",\n",
    "            \"instance_count\": 1,\n",
    "        },\n",
    "        \"candidate_specific_static_hyperparameters\": {\n",
    "            \"num_categorical_features\": '0',\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Candidates\n",
    "\n",
    "You have selected the following candidates (please run the cell below and click on the feature transformer links for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <table>\n",
       "            <tr><th>Candidate Name</th><th>Algorithm</th><th>Feature Transformer</th></tr>\n",
       "            <tr><th>dpp0-xgboost</th><td>xgboost</td><td><a href='Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp0.py'>dpp0.py</a></td></tr>\n",
       "<tr><th>dpp1-xgboost</th><td>xgboost</td><td><a href='Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp1.py'>dpp1.py</a></td></tr>\n",
       "<tr><th>dpp2-linear-learner</th><td>linear-learner</td><td><a href='Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp2.py'>dpp2.py</a></td></tr>\n",
       "<tr><th>dpp3-xgboost</th><td>xgboost</td><td><a href='Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp3.py'>dpp3.py</a></td></tr>\n",
       "<tr><th>dpp4-xgboost</th><td>xgboost</td><td><a href='Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp4.py'>dpp4.py</a></td></tr>\n",
       "<tr><th>dpp5-mlp</th><td>mlp</td><td><a href='Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp5.py'>dpp5.py</a></td></tr>\n",
       "            </table>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "automl_interactive_runner.display_candidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature engineering pipeline consists of two SageMaker jobs:\n",
    "\n",
    "1. Generated trainable data transformer Python modules like [dpp0.py](Funders-USA-SEC-data-MVP-1-artifacts/generated_module/candidate_data_processors/dpp0.py), which has been downloaded to the local file system\n",
    "2. A **training** job to train the data transformers\n",
    "3. A **batch transform** job to apply the trained transformation to the dataset to generate the algorithm compatible data\n",
    "\n",
    "The transformers and its training pipeline are built using open sourced **[sagemaker-scikit-learn-container][]** and **[sagemaker-scikit-learn-extension][]**.\n",
    "\n",
    "[sagemaker-scikit-learn-container]: https://github.com/aws/sagemaker-scikit-learn-container\n",
    "[sagemaker-scikit-learn-extension]: https://github.com/aws/sagemaker-scikit-learn-extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the Candidate Pipelines\n",
    "\n",
    "Each candidate pipeline consists of two steps, feature transformation and algorithm training.\n",
    "For efficiency first execute the feature transformation step which will generate a featurized dataset on S3\n",
    "for each pipeline.\n",
    "\n",
    "After each featurized dataset is prepared, execute a multi-algorithm tuning job that will run tuning jobs\n",
    "in parallel for each pipeline. This tuning job will execute training jobs to find the best set of\n",
    "hyper-parameters for each pipeline, as well as finding the overall best performing pipeline.\n",
    "\n",
    "### Run Data Transformation Steps\n",
    "\n",
    "Now you are ready to start execution all data transformation steps.  The cell below may take some time to finish,\n",
    "feel free to go grab a cup of coffee. To expedite the process you can set the number of `parallel_jobs` to be up to 10.\n",
    "Please check the account limits to increase the limits before increasing the number of jobs to run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-11 04:07:07,192 INFO root: [Worker_1:dpp1-xgboost]Executing step: train_data_transformer\n",
      "2021-02-11 04:07:07,195 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:07:07,207 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:07:07,529 INFO sagemaker: Creating training-job with name: Funders-US-notebook-run-11-04-05-35-dpp1-train-11-04-07-07\n",
      "\n",
      "2021-02-11 04:07:07 Starting - Starting the training job2021-02-11 04:07:11,194 INFO root: [Worker_0:dpp0-xgboost]Executing step: train_data_transformer\n",
      "2021-02-11 04:07:11,195 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:07:11,207 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:07:11,346 INFO sagemaker: Creating training-job with name: Funders-US-notebook-run-11-04-05-35-dpp0-train-11-04-07-07\n",
      "\n",
      "2021-02-11 04:07:11 Starting - Starting the training job\n",
      "2021-02-11 04:07:09 Starting - Launching requested ML instances\n",
      "2021-02-11 04:07:13 Starting - Launching requested ML instances..................................\n",
      "2021-02-11 04:08:39 Starting - Preparing the instances for training\n",
      "2021-02-11 04:08:44 Starting - Preparing the instances for training..............\n",
      "2021-02-11 04:09:19 Downloading - Downloading input data..\n",
      "2021-02-11 04:09:29 Downloading - Downloading input data..\n",
      "2021-02-11 04:09:34 Training - Downloading the training image.....\n",
      "2021-02-11 04:09:52 Training - Training image download completed. Training in progress.\n",
      "2021-02-11 04:09:53 Training - Downloading the training image.....\n",
      "2021-02-11 04:10:08 Training - Training image download completed. Training in progress.\n",
      "2021-02-11 04:10:13 Uploading - Uploading generated training model.\n",
      "2021-02-11 04:10:17 Completed - Training job completed\n",
      "2021-02-11 04:10:18,824 INFO root: [Worker_1:dpp1-xgboost]Executing step: create_transformer_model\n",
      "2021-02-11 04:10:18,953 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-02-11-04-10-18-825\n",
      "2021-02-11 04:10:19,305 INFO root: [Worker_1:dpp1-xgboost]Executing step: perform_data_transform\n",
      "2021-02-11 04:10:19,309 INFO sagemaker: Creating transform job with name: Funders-US-notebook-run-11-04-05-35-dpp1-transform-11-04-07-07\n",
      ".....\n",
      "2021-02-11 04:10:29 Uploading - Uploading generated training model.\n",
      "2021-02-11 04:10:37 Completed - Training job completed\n",
      ".2021-02-11 04:10:41,708 INFO root: [Worker_0:dpp0-xgboost]Executing step: create_transformer_model\n",
      "2021-02-11 04:10:41,730 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-02-11-04-10-41-709\n",
      ".2021-02-11 04:10:46,062 INFO root: [Worker_0:dpp0-xgboost]Executing step: perform_data_transform\n",
      "2021-02-11 04:10:46,063 INFO sagemaker: Creating transform job with name: Funders-US-notebook-run-11-04-05-35-dpp0-transform-11-04-07-07\n",
      ".................................................................................................!\n",
      "2021-02-11 04:14:50,827 INFO root: Successfully fit data transformer for dpp1-xgboost\n",
      ".2021-02-11 04:14:53,830 INFO root: [Worker_1:dpp2-linear-learner]Executing step: train_data_transformer\n",
      "2021-02-11 04:14:53,831 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:14:53,841 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:14:53,980 INFO sagemaker: Creating training-job with name: Funders-US-notebook-run-11-04-05-35-dpp2-train-11-04-07-07\n",
      "\n",
      "2021-02-11 04:14:54 Starting - Starting the training job.\n",
      "2021-02-11 04:14:56 Starting - Launching requested ML instances..............!\n",
      "2021-02-11 04:15:37,677 INFO root: Successfully fit data transformer for dpp0-xgboost\n",
      ".2021-02-11 04:15:39,678 INFO root: [Worker_0:dpp3-xgboost]Executing step: train_data_transformer\n",
      "2021-02-11 04:15:39,681 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:15:39,689 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:15:39,811 INFO sagemaker: Creating training-job with name: Funders-US-notebook-run-11-04-05-35-dpp3-train-11-04-07-07\n",
      "\n",
      "2021-02-11 04:15:39 Starting - Starting the training job.\n",
      "2021-02-11 04:15:42 Starting - Launching requested ML instances..................\n",
      "2021-02-11 04:16:30 Starting - Preparing the instances for training........\n",
      "2021-02-11 04:16:55 Starting - Preparing the instances for training......\n",
      "2021-02-11 04:17:11 Downloading - Downloading input data.......\n",
      "2021-02-11 04:17:34 Training - Downloading the training image\n",
      "2021-02-11 04:17:35 Downloading - Downloading input data....\n",
      "2021-02-11 04:17:47 Training - Training image download completed. Training in progress....\n",
      "2021-02-11 04:17:59 Uploading - Uploading generated training model\n",
      "2021-02-11 04:17:57 Training - Downloading the training image..\n",
      "2021-02-11 04:18:05 Completed - Training job completed\n",
      ".2021-02-11 04:18:13,226 INFO root: [Worker_1:dpp2-linear-learner]Executing step: create_transformer_model\n",
      "2021-02-11 04:18:13,258 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-02-11-04-18-13-227\n",
      "\n",
      "2021-02-11 04:18:12 Training - Training image download completed. Training in progress.2021-02-11 04:18:16,631 INFO root: [Worker_1:dpp2-linear-learner]Executing step: perform_data_transform\n",
      "2021-02-11 04:18:16,635 INFO sagemaker: Creating transform job with name: Funders-US-notebook-run-11-04-05-35-dpp2-transform-11-04-07-07\n",
      "...\n",
      "2021-02-11 04:18:25 Uploading - Uploading generated training model.\n",
      "2021-02-11 04:18:30 Completed - Training job completed\n",
      ".2021-02-11 04:18:32,962 INFO root: [Worker_0:dpp3-xgboost]Executing step: create_transformer_model\n",
      "2021-02-11 04:18:32,983 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-02-11-04-18-32-962\n",
      "2021-02-11 04:18:35,357 INFO root: [Worker_0:dpp3-xgboost]Executing step: perform_data_transform\n",
      "2021-02-11 04:18:35,358 INFO sagemaker: Creating transform job with name: Funders-US-notebook-run-11-04-05-35-dpp3-transform-11-04-07-07\n",
      ".............................................................................................................!\n",
      "2021-02-11 04:23:08,165 INFO root: Successfully fit data transformer for dpp2-linear-learner\n",
      ".2021-02-11 04:23:15,170 INFO root: [Worker_1:dpp4-xgboost]Executing step: train_data_transformer\n",
      "2021-02-11 04:23:15,171 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:23:15,184 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:23:15,350 INFO sagemaker: Creating training-job with name: Funders-US-notebook-run-11-04-05-35-dpp4-train-11-04-07-07\n",
      "\n",
      "2021-02-11 04:23:15 Starting - Starting the training job.\n",
      "2021-02-11 04:23:18 Starting - Launching requested ML instances....!\n",
      "2021-02-11 04:23:31,908 INFO root: Successfully fit data transformer for dpp3-xgboost\n",
      ".2021-02-11 04:23:37,914 INFO root: [Worker_0:dpp5-mlp]Executing step: train_data_transformer\n",
      "2021-02-11 04:23:37,915 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:23:37,923 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:23:38,044 INFO sagemaker: Creating training-job with name: Funders-US-notebook-run-11-04-05-35-dpp5-train-11-04-07-07\n",
      "\n",
      "2021-02-11 04:23:38 Starting - Starting the training job.\n",
      "2021-02-11 04:23:40 Starting - Launching requested ML instances..........................\n",
      "2021-02-11 04:24:49 Starting - Preparing the instances for training........\n",
      "2021-02-11 04:25:08 Starting - Preparing the instances for training............\n",
      "2021-02-11 04:25:43 Downloading - Downloading input data..\n",
      "2021-02-11 04:25:50 Downloading - Downloading input data....\n",
      "2021-02-11 04:26:03 Training - Downloading the training image..\n",
      "2021-02-11 04:26:10 Training - Downloading the training image..\n",
      "2021-02-11 04:26:19 Training - Training image download completed. Training in progress...\n",
      "2021-02-11 04:26:24 Training - Training image download completed. Training in progress....\n",
      "2021-02-11 04:26:35 Uploading - Uploading generated training model\n",
      "2021-02-11 04:26:40 Uploading - Uploading generated training model\n",
      "2021-02-11 04:26:43 Completed - Training job completed\n",
      ".2021-02-11 04:26:50,320 INFO root: [Worker_0:dpp5-mlp]Executing step: create_transformer_model\n",
      "2021-02-11 04:26:50,353 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-02-11-04-26-50-321\n",
      "\n",
      "2021-02-11 04:26:48 Completed - Training job completed\n",
      "2021-02-11 04:26:56,702 INFO root: [Worker_0:dpp5-mlp]Executing step: perform_data_transform\n",
      "2021-02-11 04:26:56,706 INFO sagemaker: Creating transform job with name: Funders-US-notebook-run-11-04-05-35-dpp5-transform-11-04-07-07\n",
      ".2021-02-11 04:26:58,766 INFO root: [Worker_1:dpp4-xgboost]Executing step: create_transformer_model\n",
      "2021-02-11 04:26:58,789 INFO sagemaker: Creating model with name: sagemaker-sklearn-automl-2021-02-11-04-26-58-767\n",
      ".2021-02-11 04:27:06,105 INFO root: [Worker_1:dpp4-xgboost]Executing step: perform_data_transform\n",
      "2021-02-11 04:27:06,107 INFO sagemaker: Creating transform job with name: Funders-US-notebook-run-11-04-05-35-dpp4-transform-11-04-07-07\n",
      ".....................................................................................................................!\n",
      "2021-02-11 04:31:58,292 INFO root: Successfully fit data transformer for dpp5-mlp\n",
      "...!\n",
      "2021-02-11 04:32:17,718 INFO root: Successfully fit data transformer for dpp4-xgboost\n",
      "2021-02-11 04:32:17,720 INFO root: Successfully fit 6 data transformers\n"
     ]
    }
   ],
   "source": [
    "automl_interactive_runner.fit_data_transformers(parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Algorithm Hyperparameter Tuning\n",
    "\n",
    "Now that the algorithm compatible transformed datasets are ready, you can start the multi-algorithm model tuning job\n",
    "to find the best predictive model. The following algorithm training job configuration for each\n",
    "algorithm is auto-generated by the AutoML Job as part of the recommendation.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. Hyperparameter ranges\n",
    "2. Objective metrics\n",
    "3. Recommended static algorithm hyperparameters.\n",
    "\n",
    "Please refers to [Xgboost tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html) and [Linear learner tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner-tuning.html) for detailed explanations of the parameters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AutoML recommendation job has recommended the following hyperparameters, objectives and accuracy metrics for\n",
    "the algorithm and problem type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_OBJECTIVE_METRICS = {\n",
    "    'xgboost': 'validation:accuracy',\n",
    "    'linear-learner': 'validation:binary_classification_accuracy',\n",
    "    'mlp': 'validation:accuracy',\n",
    "}\n",
    "\n",
    "STATIC_HYPERPARAMETERS = {\n",
    "    'xgboost': {\n",
    "        'objective': 'binary:logistic',\n",
    "        'save_model_on_termination': 'true',\n",
    "    },\n",
    "    'linear-learner': {\n",
    "        'predictor_type': 'binary_classifier',\n",
    "        'loss': 'logistic',\n",
    "        'mini_batch_size': 800,\n",
    "        'binary_classifier_model_selection_criteria': 'loss_function',\n",
    "        'num_models': 1,\n",
    "    },\n",
    "    'mlp': {\n",
    "        'problem_type': 'binary_classification',\n",
    "        'positive_example_weight_mult': 'auto',\n",
    "        'ml_application': 'mlp',\n",
    "        'use_batchnorm': 'true',\n",
    "        'activation': 'relu',\n",
    "        'warmup_epochs': 10,\n",
    "        'eval_metric': 'accuracy',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tunable hyperparameters search ranges are recommended for the Multi-Algo tuning job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.parameter import CategoricalParameter, ContinuousParameter, IntegerParameter\n",
    "\n",
    "ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES = {\n",
    "    'xgboost': {\n",
    "        'num_round': IntegerParameter(2, 1024, scaling_type='Logarithmic'),\n",
    "        'max_depth': IntegerParameter(2, 8, scaling_type='Logarithmic'),\n",
    "        'eta': ContinuousParameter(1e-3, 1.0, scaling_type='Logarithmic'),\n",
    "        'gamma': ContinuousParameter(1e-6, 64.0, scaling_type='Logarithmic'),\n",
    "        'min_child_weight': ContinuousParameter(1e-6, 32.0, scaling_type='Logarithmic'),\n",
    "        'subsample': ContinuousParameter(0.5, 1.0, scaling_type='Linear'),\n",
    "        'colsample_bytree': ContinuousParameter(0.3, 1.0, scaling_type='Linear'),\n",
    "        'lambda': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "        'alpha': ContinuousParameter(1e-6, 2.0, scaling_type='Logarithmic'),\n",
    "    },\n",
    "    'linear-learner': {\n",
    "        'wd': ContinuousParameter(1e-7, 1.0, scaling_type='Logarithmic'),\n",
    "        'l1': ContinuousParameter(1e-7, 1.0, scaling_type='Logarithmic'),\n",
    "        'learning_rate': ContinuousParameter(1e-5, 1.0, scaling_type='Logarithmic'),\n",
    "    },\n",
    "    'mlp': {\n",
    "        'mini_batch_size': IntegerParameter(128, 512, scaling_type='Linear'),\n",
    "        'learning_rate': ContinuousParameter(1e-6, 1e-2, scaling_type='Logarithmic'),\n",
    "        'weight_decay': ContinuousParameter(1e-12, 1e-2, scaling_type='Logarithmic'),\n",
    "        'dropout_prob': ContinuousParameter(0.25, 0.5, scaling_type='Linear'),\n",
    "        'embedding_size_factor': ContinuousParameter(0.65, 0.95, scaling_type='Linear'),\n",
    "        'network_type': CategoricalParameter(['feedforward', 'widedeep']),\n",
    "        'layers': CategoricalParameter(['256', '50, 25', '100, 50', '200, 100', '256, 128', '300, 150', '200, 100, 50']),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Multi-Algorithm Tuner Input\n",
    "\n",
    "To use the multi-algorithm HPO tuner, prepare some inputs and parameters. Prepare a dictionary whose key is the name of the trained pipeline candidates and the values are respectively:\n",
    "\n",
    "1. Estimators for the recommended algorithm\n",
    "2. Hyperparameters search ranges\n",
    "3. Objective metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_algo_tuning_parameters = automl_interactive_runner.prepare_multi_algo_parameters(\n",
    "    objective_metrics=ALGORITHM_OBJECTIVE_METRICS,\n",
    "    static_hyperparameters=STATIC_HYPERPARAMETERS,\n",
    "    hyperparameters_search_ranges=ALGORITHM_TUNABLE_HYPERPARAMETER_RANGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you prepare the inputs data to the multi-algo tuner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_algo_tuning_inputs = automl_interactive_runner.prepare_multi_algo_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Create Multi-Algorithm Tuner\n",
    "\n",
    "With the recommended Hyperparameter ranges and the transformed dataset, create a multi-algorithm model tuning job\n",
    "that coordinates hyper parameter optimizations across the different possible algorithms and feature processing strategies.\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. Tuner strategy: [Bayesian](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Bayesian_optimization), [Random Search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Random_search)\n",
    "2. Objective type: `Minimize`, `Maximize`, see [optimization](https://en.wikipedia.org/wiki/Mathematical_optimization)\n",
    "3. Max Job size: the max number of training jobs HPO would be launching to run experiments. Note the default value is **250**\n",
    "    which is the default of the managed flow.\n",
    "4. Parallelism. Number of jobs that will be executed in parallel. Higher value will expedite the tuning process.\n",
    "    Please check the account limits to increase the limits before increasing the number of jobs to run in parallel\n",
    "5. Please use a different tuning job name if you re-run this cell after applied customizations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "base_tuning_job_name = \"{}-tuning\".format(AUTOML_LOCAL_RUN_CONFIG.local_automl_job_name)\n",
    "\n",
    "tuner = HyperparameterTuner.create(\n",
    "    base_tuning_job_name=base_tuning_job_name,\n",
    "    strategy='Bayesian',\n",
    "    objective_type='Maximize',\n",
    "    max_parallel_jobs=2,\n",
    "    max_jobs=250,\n",
    "    **multi_algo_tuning_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Multi-Algorithm Tuning\n",
    "\n",
    "Now you are ready to start running the **Multi-Algo Tuning** job. After the job is finished, store the tuning job name which you use to select models in the next section.\n",
    "The tuning process will take some time, please track the progress in the Amazon SageMaker Hyperparameter tuning jobs console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-11 04:32:18,325 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:32:18,334 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:32:18,335 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:32:18,345 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:32:18,346 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:32:18,354 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:32:18,355 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:32:18,363 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:32:18,364 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:32:18,372 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:32:18,374 INFO sagemaker.image_uris: Defaulting to the only supported framework/algorithm version: latest.\n",
      "2021-02-11 04:32:18,383 INFO sagemaker.image_uris: Ignoring unnecessary instance type: None.\n",
      "2021-02-11 04:32:18,393 INFO sagemaker: Creating hyperparameter tuning job with name: Funders-US-notebook--210211-0432\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Run tuning\n",
    "tuner.fit(inputs=multi_algo_tuning_inputs, include_cls_metadata=None)\n",
    "tuning_job_name = tuner.latest_tuning_job.name\n",
    "\n",
    "display(\n",
    "    Markdown(f\"Tuning Job {tuning_job_name} started, please track the progress from [here](https://{AUTOML_LOCAL_RUN_CONFIG.region}.console.aws.amazon.com/sagemaker/home?region={AUTOML_LOCAL_RUN_CONFIG.region}#/hyper-tuning-jobs/{tuning_job_name})\"))\n",
    "\n",
    "# Wait for tuning job to finish\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Deployment\n",
    "\n",
    "This section guides you through the model selection process. Afterward, you construct an inference pipeline\n",
    "on Amazon SageMaker to host the best candidate.\n",
    "\n",
    "Because you executed the feature transformation and algorithm training in two separate steps, you now need to manually\n",
    "link each trained model with the feature transformer that it is associated with. When running a regular Amazon\n",
    "SageMaker Autopilot job, this will automatically be done for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Job Result Overview\n",
    "\n",
    "The performance of each candidate pipeline can be viewed as a Pandas dataframe. For more interactive usage please\n",
    "refers to [model tuning monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-monitor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout_prob</th>\n",
       "      <th>embedding_size_factor</th>\n",
       "      <th>layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mini_batch_size</th>\n",
       "      <th>network_type</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "      <th>TrainingJobDefinitionName</th>\n",
       "      <th>alpha</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>eta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lambda</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>num_round</th>\n",
       "      <th>subsample</th>\n",
       "      <th>l1</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.478083</td>\n",
       "      <td>0.934566</td>\n",
       "      <td>50, 25</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>397.0</td>\n",
       "      <td>widedeep</td>\n",
       "      <td>1.937422e-06</td>\n",
       "      <td>Funders-US-notebook--210211-0432-007-8fd52f79</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.579412</td>\n",
       "      <td>2021-02-11 04:44:42+00:00</td>\n",
       "      <td>2021-02-11 04:46:17+00:00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>dpp5-mlp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Funders-US-notebook--210211-0432-033-80d3bacd</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.573530</td>\n",
       "      <td>2021-02-11 05:31:18+00:00</td>\n",
       "      <td>2021-02-11 05:32:49+00:00</td>\n",
       "      <td>91.0</td>\n",
       "      <td>dpp1-xgboost</td>\n",
       "      <td>0.026206</td>\n",
       "      <td>0.849549</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>2.366705</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.766896</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.66897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.482338</td>\n",
       "      <td>0.887138</td>\n",
       "      <td>50, 25</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>281.0</td>\n",
       "      <td>widedeep</td>\n",
       "      <td>3.838679e-06</td>\n",
       "      <td>Funders-US-notebook--210211-0432-247-547e3f52</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>2021-02-11 12:58:34+00:00</td>\n",
       "      <td>2021-02-11 13:00:09+00:00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>dpp5-mlp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.480180</td>\n",
       "      <td>0.902370</td>\n",
       "      <td>50, 25</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>388.0</td>\n",
       "      <td>widedeep</td>\n",
       "      <td>1.380099e-07</td>\n",
       "      <td>Funders-US-notebook--210211-0432-041-70acfa5f</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>2021-02-11 05:48:01+00:00</td>\n",
       "      <td>2021-02-11 05:49:36+00:00</td>\n",
       "      <td>95.0</td>\n",
       "      <td>dpp5-mlp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.459914</td>\n",
       "      <td>0.917667</td>\n",
       "      <td>50, 25</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>455.0</td>\n",
       "      <td>widedeep</td>\n",
       "      <td>6.073554e-07</td>\n",
       "      <td>Funders-US-notebook--210211-0432-107-413444cb</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.567647</td>\n",
       "      <td>2021-02-11 08:08:37+00:00</td>\n",
       "      <td>2021-02-11 08:10:34+00:00</td>\n",
       "      <td>117.0</td>\n",
       "      <td>dpp5-mlp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dropout_prob  embedding_size_factor  layers  learning_rate  \\\n",
       "243      0.478083               0.934566  50, 25       0.000303   \n",
       "217           NaN                    NaN     NaN            NaN   \n",
       "3        0.482338               0.887138  50, 25       0.000956   \n",
       "209      0.480180               0.902370  50, 25       0.000338   \n",
       "143      0.459914               0.917667  50, 25       0.000589   \n",
       "\n",
       "     mini_batch_size network_type  weight_decay  \\\n",
       "243            397.0     widedeep  1.937422e-06   \n",
       "217              NaN          NaN           NaN   \n",
       "3              281.0     widedeep  3.838679e-06   \n",
       "209            388.0     widedeep  1.380099e-07   \n",
       "143            455.0     widedeep  6.073554e-07   \n",
       "\n",
       "                                   TrainingJobName TrainingJobStatus  \\\n",
       "243  Funders-US-notebook--210211-0432-007-8fd52f79         Completed   \n",
       "217  Funders-US-notebook--210211-0432-033-80d3bacd         Completed   \n",
       "3    Funders-US-notebook--210211-0432-247-547e3f52         Completed   \n",
       "209  Funders-US-notebook--210211-0432-041-70acfa5f         Completed   \n",
       "143  Funders-US-notebook--210211-0432-107-413444cb         Completed   \n",
       "\n",
       "     FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "243             0.579412 2021-02-11 04:44:42+00:00 2021-02-11 04:46:17+00:00   \n",
       "217             0.573530 2021-02-11 05:31:18+00:00 2021-02-11 05:32:49+00:00   \n",
       "3               0.573529 2021-02-11 12:58:34+00:00 2021-02-11 13:00:09+00:00   \n",
       "209             0.573529 2021-02-11 05:48:01+00:00 2021-02-11 05:49:36+00:00   \n",
       "143             0.567647 2021-02-11 08:08:37+00:00 2021-02-11 08:10:34+00:00   \n",
       "\n",
       "     TrainingElapsedTimeSeconds TrainingJobDefinitionName     alpha  \\\n",
       "243                        95.0                  dpp5-mlp       NaN   \n",
       "217                        91.0              dpp1-xgboost  0.026206   \n",
       "3                          95.0                  dpp5-mlp       NaN   \n",
       "209                        95.0                  dpp5-mlp       NaN   \n",
       "143                       117.0                  dpp5-mlp       NaN   \n",
       "\n",
       "     colsample_bytree       eta     gamma    lambda  max_depth  \\\n",
       "243               NaN       NaN       NaN       NaN        NaN   \n",
       "217          0.849549  0.008609  2.366705  0.000999        6.0   \n",
       "3                 NaN       NaN       NaN       NaN        NaN   \n",
       "209               NaN       NaN       NaN       NaN        NaN   \n",
       "143               NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "     min_child_weight  num_round  subsample  l1  wd  \n",
       "243               NaN        NaN        NaN NaN NaN  \n",
       "217          0.766896       73.0    0.66897 NaN NaN  \n",
       "3                 NaN        NaN        NaN NaN NaN  \n",
       "209               NaN        NaN        NaN NaN NaN  \n",
       "143               NaN        NaN        NaN NaN NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "SAGEMAKER_SESSION = AUTOML_LOCAL_RUN_CONFIG.sagemaker_session\n",
    "SAGEMAKER_ROLE = AUTOML_LOCAL_RUN_CONFIG.role\n",
    "\n",
    "tuner_analytics = HyperparameterTuningJobAnalytics(\n",
    "    tuner.latest_tuning_job.name, sagemaker_session=SAGEMAKER_SESSION)\n",
    "\n",
    "df_tuning_job_analytics = tuner_analytics.dataframe()\n",
    "\n",
    "# Sort the tuning job analytics by the final metrics value\n",
    "df_tuning_job_analytics.sort_values(\n",
    "    by=['FinalObjectiveValue'],\n",
    "    inplace=True,\n",
    "    ascending=False if tuner.objective_type == \"Maximize\" else True)\n",
    "\n",
    "# Show detailed analytics for the top 20 models\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', 60)\n",
    "df_tuning_job_analytics.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best training job can be selected as below:\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong>Tips: </strong>\n",
    "You could select alternative job by using the value from `TrainingJobName` column above and assign to `best_training_job` below\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Multi Algorithm HPO training job name is Funders-US-notebook--210211-0432-007-8fd52f79\n"
     ]
    }
   ],
   "source": [
    "attached_tuner = HyperparameterTuner.attach(tuner.latest_tuning_job.name, sagemaker_session=SAGEMAKER_SESSION)\n",
    "best_training_job = attached_tuner.best_training_job()\n",
    "\n",
    "print(\"Best Multi Algorithm HPO training job name is {}\".format(best_training_job))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking Best Training Job with Feature Pipelines\n",
    "\n",
    "Finally, deploy the best training job to Amazon SageMaker along with its companion feature engineering models.\n",
    "At the end of the section, you get an endpoint that's ready to serve online inference or start batch transform jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy a [PipelineModel](https://sagemaker.readthedocs.io/en/stable/pipeline.html) that has multiple containers of the following:\n",
    "\n",
    "1. Data Transformation Container: a container built from the model we selected and trained during the data transformer sections\n",
    "2. Algorithm Container: a container built from the trained model we selected above from the best HPO training job.\n",
    "3. Inverse Label Transformer Container: a container that converts numerical intermediate prediction value back to non-numerical label value.\n",
    "\n",
    "Get both best data transformation model and algorithm model from best training job and create an pipeline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-11 20:54:18,578 INFO root: Chosen Data Processing pipeline candidate name is dpp5-mlp\n",
      "\n",
      "2021-02-11 04:28:04 Starting - Preparing the instances for training\n",
      "2021-02-11 04:28:04 Downloading - Downloading input data\n",
      "2021-02-11 04:28:04 Training - Training image download completed. Training in progress.\n",
      "2021-02-11 04:28:04 Uploading - Uploading generated training model\n",
      "2021-02-11 04:28:04 Completed - Training job completed\n",
      "\n",
      "2021-02-11 04:46:17 Starting - Preparing the instances for training\n",
      "2021-02-11 04:46:17 Downloading - Downloading input data\n",
      "2021-02-11 04:46:17 Training - Training image download completed. Training in progress.\n",
      "2021-02-11 04:46:17 Uploading - Uploading generated training model\n",
      "2021-02-11 04:46:17 Completed - Training job completed\n",
      "\n",
      "2021-02-11 04:28:04 Starting - Preparing the instances for training\n",
      "2021-02-11 04:28:04 Downloading - Downloading input data\n",
      "2021-02-11 04:28:04 Training - Training image download completed. Training in progress.\n",
      "2021-02-11 04:28:04 Uploading - Uploading generated training model\n",
      "2021-02-11 04:28:04 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import PipelineModel\n",
    "from sagemaker_automl import select_inference_output\n",
    "\n",
    "# Get a data transformation model from chosen candidate\n",
    "best_candidate = automl_interactive_runner.choose_candidate(df_tuning_job_analytics, best_training_job)\n",
    "best_data_transformer_model = best_candidate.get_data_transformer_model(role=SAGEMAKER_ROLE, sagemaker_session=SAGEMAKER_SESSION)\n",
    "\n",
    "# Our first data transformation container will always return recordio-protobuf format\n",
    "best_data_transformer_model.env[\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\"] = 'application/x-recordio-protobuf'\n",
    "# Add environment variable for sparse encoding\n",
    "if best_candidate.data_transformer_step.sparse_encoding:\n",
    "    best_data_transformer_model.env[\"AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF\"] = '1'\n",
    "\n",
    "# Get a algo model from chosen training job of the candidate\n",
    "algo_estimator = Estimator.attach(best_training_job)\n",
    "best_algo_model = algo_estimator.create_model(**best_candidate.algo_step.get_inference_container_config())\n",
    "\n",
    "# Final pipeline model is composed of data transformation models and algo model and an\n",
    "# inverse label transform model if we need to transform the intermediates back to non-numerical value\n",
    "model_containers = [best_data_transformer_model, best_algo_model]\n",
    "if best_candidate.transforms_label:\n",
    "    model_containers.append(best_candidate.get_data_transformer_model(\n",
    "        transform_mode=\"inverse-label-transform\",\n",
    "        role=SAGEMAKER_ROLE,\n",
    "        sagemaker_session=SAGEMAKER_SESSION))\n",
    "\n",
    "# This model can emit response ['predicted_label', 'probability', 'labels', 'probabilities']. To enable the model to emit one or more\n",
    "# of the response content, pass the keys to `output_key` keyword argument in the select_inference_output method.\n",
    "\n",
    "model_containers = select_inference_output(\"BinaryClassification\", model_containers, output_keys=['predicted_label'])\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=\"AutoML-{}\".format(AUTOML_LOCAL_RUN_CONFIG.local_automl_job_name),\n",
    "    role=SAGEMAKER_ROLE,\n",
    "    models=model_containers,\n",
    "    vpc_config=AUTOML_LOCAL_RUN_CONFIG.vpc_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to show alg labels next to true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>-0.5519929984313154</th>\n",
       "      <th>-1.1190904348376265</th>\n",
       "      <th>-0.6571774950022166</th>\n",
       "      <th>-0.17057581702560418</th>\n",
       "      <th>-0.13056050055005414</th>\n",
       "      <th>-0.33787003881689676</th>\n",
       "      <th>-0.2581718569154313</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>-0.2884414630948068</th>\n",
       "      <th>-0.24803741794451586</th>\n",
       "      <th>-0.3110545369120166</th>\n",
       "      <th>0.053473375144112066</th>\n",
       "      <th>0.31297971825027526</th>\n",
       "      <th>0.19748155461069614</th>\n",
       "      <th>-0.29817118085353106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.794424</td>\n",
       "      <td>1.133006</td>\n",
       "      <td>-0.131178</td>\n",
       "      <td>-0.117575</td>\n",
       "      <td>0.103318</td>\n",
       "      <td>-0.330313</td>\n",
       "      <td>0.199294</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.275212</td>\n",
       "      <td>0.935755</td>\n",
       "      <td>1.032625</td>\n",
       "      <td>-0.311055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.326807</td>\n",
       "      <td>-1.354797</td>\n",
       "      <td>-0.298171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.746532</td>\n",
       "      <td>0.969302</td>\n",
       "      <td>0.570155</td>\n",
       "      <td>0.145832</td>\n",
       "      <td>0.111127</td>\n",
       "      <td>0.296923</td>\n",
       "      <td>0.530930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061946</td>\n",
       "      <td>0.045306</td>\n",
       "      <td>-0.311055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.529368</td>\n",
       "      <td>0.457061</td>\n",
       "      <td>-0.298171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553992</td>\n",
       "      <td>1.133006</td>\n",
       "      <td>-0.481844</td>\n",
       "      <td>-0.170576</td>\n",
       "      <td>-0.133179</td>\n",
       "      <td>-0.337870</td>\n",
       "      <td>-0.267306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.288441</td>\n",
       "      <td>-0.248037</td>\n",
       "      <td>-0.311055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304929</td>\n",
       "      <td>0.240386</td>\n",
       "      <td>-0.298171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.455820</td>\n",
       "      <td>-1.252392</td>\n",
       "      <td>-0.832511</td>\n",
       "      <td>-0.163509</td>\n",
       "      <td>-0.133179</td>\n",
       "      <td>-0.281476</td>\n",
       "      <td>-0.267306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.288441</td>\n",
       "      <td>-0.248037</td>\n",
       "      <td>-0.311055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312980</td>\n",
       "      <td>0.240386</td>\n",
       "      <td>-0.298171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.551993</td>\n",
       "      <td>-1.119090</td>\n",
       "      <td>-0.481844</td>\n",
       "      <td>-0.088022</td>\n",
       "      <td>-0.131860</td>\n",
       "      <td>0.250008</td>\n",
       "      <td>-0.263898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.040165</td>\n",
       "      <td>-0.227759</td>\n",
       "      <td>-0.277925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156266</td>\n",
       "      <td>0.185507</td>\n",
       "      <td>-0.298171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1.0  -0.5519929984313154  -1.1190904348376265  -0.6571774950022166  \\\n",
       "0  0.0             0.794424             1.133006            -0.131178   \n",
       "1  1.0             1.746532             0.969302             0.570155   \n",
       "2  0.0             0.553992             1.133006            -0.481844   \n",
       "3  0.0            -0.455820            -1.252392            -0.832511   \n",
       "4  1.0            -0.551993            -1.119090            -0.481844   \n",
       "\n",
       "   -0.17057581702560418  -0.13056050055005414  -0.33787003881689676  \\\n",
       "0             -0.117575              0.103318             -0.330313   \n",
       "1              0.145832              0.111127              0.296923   \n",
       "2             -0.170576             -0.133179             -0.337870   \n",
       "3             -0.163509             -0.133179             -0.281476   \n",
       "4             -0.088022             -0.131860              0.250008   \n",
       "\n",
       "   -0.2581718569154313       0.0     0.0.1  -0.2884414630948068  \\\n",
       "0             0.199294  0.000868  0.275212             0.935755   \n",
       "1             0.530930  0.000000  0.000000             0.061946   \n",
       "2            -0.267306  0.000000  0.000000            -0.288441   \n",
       "3            -0.267306  0.000000  0.000000            -0.288441   \n",
       "4            -0.263898  0.000000  0.000000            -0.040165   \n",
       "\n",
       "   -0.24803741794451586  -0.3110545369120166  0.053473375144112066  \\\n",
       "0              1.032625            -0.311055                   0.0   \n",
       "1              0.045306            -0.311055                   0.0   \n",
       "2             -0.248037            -0.311055                   0.0   \n",
       "3             -0.248037            -0.311055                   0.0   \n",
       "4             -0.227759            -0.277925                   0.0   \n",
       "\n",
       "   0.31297971825027526  0.19748155461069614  -0.29817118085353106  \n",
       "0            -1.326807            -1.354797             -0.298171  \n",
       "1             0.529368             0.457061             -0.298171  \n",
       "2             0.304929             0.240386             -0.298171  \n",
       "3             0.312980             0.240386             -0.298171  \n",
       "4             0.156266             0.185507             -0.298171  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_create_sagemaker_pipeline_model',\n",
       " 'delete_model',\n",
       " 'deploy',\n",
       " 'enable_network_isolation',\n",
       " 'endpoint_name',\n",
       " 'models',\n",
       " 'name',\n",
       " 'pipeline_container_def',\n",
       " 'predictor_cls',\n",
       " 'role',\n",
       " 'sagemaker_session',\n",
       " 'transformer',\n",
       " 'vpc_config']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m           PipelineModel\n",
       "\u001b[0;31mString form:\u001b[0m    <sagemaker.pipeline.PipelineModel object at 0x7f5799ba16d0>\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/sagemaker/pipeline.py\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A pipeline of SageMaker `Model` instances.\n",
       "\n",
       "This pipeline can be deployed as an `Endpoint` on SageMaker.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Initialize a SageMaker `Model` instance.\n",
       "\n",
       "The `Model` can be used to build an Inference Pipeline comprising of\n",
       "multiple model containers.\n",
       "\n",
       "Args:\n",
       "    models (list[sagemaker.Model]): For using multiple containers to\n",
       "        build an inference pipeline, you can pass a list of\n",
       "        ``sagemaker.Model`` objects in the order you want the inference\n",
       "        to happen.\n",
       "    role (str): An AWS IAM role (either name or full ARN). The Amazon\n",
       "        SageMaker training jobs and APIs that create Amazon SageMaker\n",
       "        endpoints use this role to access training data and model\n",
       "        artifacts. After the endpoint is created, the inference code\n",
       "        might use the IAM role, if it needs to access an AWS resource.\n",
       "    predictor_cls (callable[string, sagemaker.session.Session]): A\n",
       "        function to call to create a predictor (default: None). If not\n",
       "        None, ``deploy`` will return the result of invoking this\n",
       "        function on the created endpoint name.\n",
       "    name (str): The model name. If None, a default model name will be\n",
       "        selected on each ``deploy``.\n",
       "    vpc_config (dict[str, list[str]]): The VpcConfig set on the model\n",
       "        (default: None)\n",
       "        * 'Subnets' (list[str]): List of subnet ids.\n",
       "        * 'SecurityGroupIds' (list[str]): List of security group ids.\n",
       "    sagemaker_session (sagemaker.session.Session): A SageMaker Session\n",
       "        object, used for SageMaker interactions (default: None). If not\n",
       "        specified, one is created using the default AWS configuration\n",
       "        chain.\n",
       "    enable_network_isolation (bool): Default False. if True, enables\n",
       "        network isolation in the endpoint, isolating the model\n",
       "        container. No inbound or outbound network calls can be made to\n",
       "        or from the model container.Boolean\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load in validation set to df\n",
    "path = 's3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1/Funders-US-notebook-run-11-04-05-35/transformed-data/dpp0/csv/validation/chunk_0.csv.out'\n",
    "val_df = pd.read_csv(path)\n",
    "# df_0to5 = pd.read_csv(path)\n",
    "# path = 's3://sagemaker-us-east-1-570124035543/export-flow-04-21-57-21-dd5ae906/machine-learning-output/autopilot-output/Funders-USA-SEC-data-MVP-1/Funders-US-notebook-run-11-04-05-35/transformed-data/dpp0/csv/validation/chunk_1.csv.out'\n",
    "# df_6to10 = pd.read_csv(path)\n",
    "# val_df = df_0to5.append(df_6to10)\n",
    "display(val_df.head(5))\n",
    "\n",
    "\n",
    "predictor = pipeline_model.predictor_cls()\n",
    "# get predicitons\n",
    "# model_predictions = predictor.predict(val_df)\n",
    "# display(model_predictions)\n",
    "\n",
    "# val_df.insert(1,'model_predictions', model_predictions)\n",
    "# ?algo_estimator\n",
    "# ?best_algo_model\n",
    "?pipeline_model\n",
    "dir(pipeline_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying Best Pipeline\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Available Knobs</strong>\n",
    "\n",
    "1. You can customize the initial instance count and instance type used to deploy this model.\n",
    "2. Endpoint name can be changed to avoid conflict with existing endpoints.\n",
    "\n",
    "</div>\n",
    "\n",
    "Finally, deploy the model to SageMaker to make it functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.deploy(initial_instance_count=1,\n",
    "                      instance_type='ml.m5.2xlarge',\n",
    "                      endpoint_name=pipeline_model.name,\n",
    "                      wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you could visit the sagemaker\n",
    "[endpoint console page](https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints) to find the deployed endpoint (it'll take a few minutes to be in service).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <strong>To rerun this notebook, delete or change the name of your endpoint!</strong> <br>\n",
    "If you rerun this notebook, you'll run into an error on the last step because the endpoint already exists. You can either delete the endpoint from the endpoint console page or you can change the <code>endpoint_name</code> in the previous code block.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
